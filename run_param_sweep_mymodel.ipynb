{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import imageio as iio\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#AIRXD model import\n",
    "\n",
    "from airxd_cnn.cnn import ARIXD_CNN as cmodel\n",
    "from airxd.model import ARIXD\n",
    "from airxd.dataset import Dataset, parse_imctrl\n",
    "from torchvision.transforms import v2\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import airxd_cnn\n",
    "from airxd_cnn.transforms import powder_normalize\n",
    "from airxd_cnn.powder_dataset_v2 import powder_dset\n",
    "from sklearn.metrics import confusion_matrix as CM\n",
    "import shutil\n",
    "#In the line below, filter out for any names with 'normalized'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_pred(model, train_classes, valid_path,\n",
    "               results, repeat_idx):\n",
    "    '''\n",
    "    This runs a simple model validation for one trained model across each of the different\n",
    "    experiments (classes). \n",
    "\n",
    "    Outputs:\n",
    "        valid_acc: (n) array of validation accuracies for n classes\n",
    "    '''\n",
    "\n",
    "    for i in range(len(train_classes)):\n",
    "        class_valid_paths = [f for f in valid_path if f.split('/')[1] == train_classes[i]]\n",
    "        class_valid_masks = [os.path.join(os.path.dirname(path), \"mask\",\n",
    "                                          os.path.basename(path).replace(\".tif\", \"_mask.tif\")) for path in class_valid_paths]\n",
    "        \n",
    "        \n",
    "        for image_idxs in range(len(class_valid_paths)):\n",
    "            #Get image and label. The predict method normalizes\n",
    "            image_file = class_valid_paths[image_idxs]\n",
    "            label_file = class_valid_masks[image_idxs]\n",
    "            labels = np.array(iio.v2.volread(label_file))\n",
    "\n",
    "            #Predict (noprmalize built in)\n",
    "            pred = model.predict_old(image_file)\n",
    "\n",
    "            #Calculate CM and append to results\n",
    "            single_cm = calculate_CM(pred, labels)\n",
    "\n",
    "            #Add to results\n",
    "            results[i,repeat_idx,:] += single_cm\n",
    "\n",
    "def calculate_CM(pred, labels):\n",
    "    matrix = CM(labels.ravel(), pred.ravel())\n",
    "    matrix_flat = matrix.ravel()\n",
    "    return matrix_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_and_val_subsets(directory_train, class_paths, subset_size):\n",
    "    #Path to normalized image data for training. Normalization was done beforehand\n",
    "    train_image_paths = []\n",
    "    #Path to mask data for training, in a separate location than the normalized image data\n",
    "    train_mask_paths = []\n",
    "    #Path to raw image data for validation\n",
    "    val_paths = []\n",
    "\n",
    "    for path_to_class in class_paths:\n",
    "        path_identifier = path_to_class + '/' + '*.tif'\n",
    "\n",
    "        #Find the normalized sample path\n",
    "        sample_paths = glob(path_identifier)\n",
    "        sample_norm_paths = [os.path.join(directory_train,\n",
    "                                          os.path.basename(path).replace(\".tif\", \"_norm.tif\")) for path in sample_paths]\n",
    "\n",
    "        #Find mask path\n",
    "        mask_paths = [f for f in glob(path_to_class + '/masks/*.tif')]\n",
    "\n",
    "        #Sort sample_paths and mask_paths to ensure uniformity\n",
    "        sample_paths.sort(key=lambda x: x.split('/')[-1])\n",
    "        sample_norm_paths.sort(key=lambda x: x.split('/')[-1])\n",
    "        mask_paths.sort(key=lambda x: x.split('/')[-1].split('_mask')[0])\n",
    "        \n",
    "        #Generate random index subset\n",
    "        n_images = len(sample_paths)\n",
    "        train_subset_indices = list(np.random.choice(n_images, subset_size, replace=False))\n",
    "        val_subset_indices = list(set(range(n_images)) - set(train_subset_indices))\n",
    "\n",
    "        #Append correct paths to train image and masks, as well as validation paths\n",
    "        train_image_paths.extend([sample_norm_paths[i] for i in train_subset_indices])\n",
    "        train_mask_paths.extend([mask_paths[i] for i in train_subset_indices])\n",
    "        val_paths.extend([sample_paths[i] for i in val_subset_indices])\n",
    "\n",
    "    return train_image_paths, train_mask_paths, val_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creates normalized images if they don't exist, does nothing if they do\n",
    "train_image_paths, train_mask_paths, val_paths = create_train_and_val_subsets(normalized_train_dir,class_paths,subset_size = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airxd_cnn.transforms import RandomRotation, RandomFlip\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from airxd_cnn.model import ARIXD_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define transforms\n",
    "from airxd_cnn.powder_dataset_v2 import powder_dset\n",
    "\n",
    "#List of acceptable classes for training\n",
    "train_classes = ['Nickel', 'battery1', 'battery2', 'battery3', 'battery4']\n",
    "\n",
    "#Define class_paths as any directories in classes\n",
    "\n",
    "class_paths = [f for f in glob('data/*') if f.split('/')[-1] in train_classes]\n",
    "mask_paths = [f for f in glob('data/*/masks/*.tif') if f.split('/')[1] in train_classes]\n",
    "\n",
    "#Normalize images within each class folder and save in separate subfolder\n",
    "normalized_train_dir = 'data/normalized_train'\n",
    "\n",
    "#Transforms\n",
    "transform_pipeline = v2.Compose([\n",
    "    RandomRotation(),\n",
    "    RandomFlip()\n",
    "])\n",
    "\n",
    "#Other relevant params\n",
    "other_params = {\"transforms\": transform_pipeline,\n",
    "          \"input_map_path\": 'data/input_mmap',\n",
    "          \"target_map_path\": 'data/target_mmap',\n",
    "          \"device\": 'cuda:0',\n",
    "          \"minority_threshold\": 30,\n",
    "          \"create_memmap\": True}\n",
    "\n",
    "#Model parameters\n",
    "training_params = {'device': 'cuda:0',\n",
    "                   'amp': False,\n",
    "                   'clip_value': None,\n",
    "                   'epoch': 20,\n",
    "                   'batch_size': batch_size,\n",
    "                   'shuffle': True,\n",
    "                   'drop_last': True,\n",
    "                   'lr_rate': 1e-2,\n",
    "                   'weights': [1.0, 10.0],\n",
    "                   'save_path': 'models_scratch'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters for paper replication\n",
    "N_sizes = [128, 256]\n",
    "N_epochs = [10, 20, 30]\n",
    "results_master = {}\n",
    "n_repeats = 5\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop everything here and save results temporarily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in N_sizes:\n",
    "    for epoch in N_epochs:\n",
    "        \n",
    "        #Quilter parameters\n",
    "        side_crop = 20\n",
    "        image_d = 2880\n",
    "        M = N // 2\n",
    "        B = M // 4\n",
    "        quilter_params = {'Y': image_d - 2*side_crop,\n",
    "                        'X': image_d - 2*side_crop,\n",
    "                        'window': (N, N),\n",
    "                        'step': (M, M),\n",
    "                        'border': (B, B),\n",
    "                        'border_weight': 0,\n",
    "                        'crop': side_crop}\n",
    "        \n",
    "        #Validation predictions\n",
    "        results = np.zeros((len(train_classes),n_repeats,4))\n",
    "        \n",
    "        for i in range(n_repeats):\n",
    "        \n",
    "            #Dataset randomization for training\n",
    "            train_image_paths, train_mask_paths, val_paths = create_train_and_val_subsets(normalized_train_dir,class_paths,subset_size = 3) \n",
    "            #Sorting to ensure 1:1 correspondence\n",
    "            train_image_paths.sort(key=lambda x: x.split('/')[-1].split('_norm')[0])\n",
    "            train_mask_paths.sort(key=lambda x: x.split('/')[-1].split('_mask')[0])\n",
    "            \n",
    "            #Create dataset object\n",
    "            train_dataset = powder_dset(train_image_paths, train_mask_paths, quilter_params, **other_params)\n",
    "\n",
    "            #Create dataloader\n",
    "            train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "            #Model specifications\n",
    "            #Define TUNet params (from dlsia)\n",
    "            model_params = {'image_shape': (N, N),\n",
    "                    'in_channels': 1,\n",
    "                    'out_channels': 2,\n",
    "                    'base_channels': 8,\n",
    "                    'growth_rate': 2,\n",
    "                    'depth': 4}\n",
    "            \n",
    "            #Setting model params\n",
    "            training_params['epoch'] = epoch\n",
    "\n",
    "            #Model training\n",
    "            cnn_model = ARIXD_CNN(model_params, training_params, quilter_params)\n",
    "\n",
    "            #Don't care about validation here, because we evaluate afterwards\n",
    "            cnn_model.train(train_loader, train_loader)\n",
    "\n",
    "            #Validation predictions\n",
    "            valid_pred(cnn_model, train_classes, val_paths,\n",
    "                       results, i)\n",
    "            \n",
    "        tn = results[:,:,0] / (results[:,:,0] + results[:,:,1] + 1)\n",
    "        tp = results[:,:,3] / (results[:,:,3] + results[:,:,2] + 1)\n",
    "\n",
    "        results_master[(N, epoch)] = np.stack((tn, tp), axis = 2)\n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airxd_cnn_fresh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
