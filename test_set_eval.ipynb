{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from airxd_cnn.cnn import ARIXD_CNN as cmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test list files in directory\n",
    "dir = 'data/battery1/masks'\n",
    "#List all files in dir\n",
    "files = os.listdir(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 6, 3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "random.sample(range(0, 11), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Params and CNN itself\n",
    "N = 256\n",
    "M = N // 2\n",
    "B = M // 4\n",
    "quilter_params = {'Y': 2880, 'X': 2880,\n",
    "                  'window': (N, N),\n",
    "                  'step': (M, M),\n",
    "                  'border': (B, B),\n",
    "                  'border_weight': 0}\n",
    "\n",
    "# TUNet params\n",
    "model_params = {'image_shape': (2880, 2880),\n",
    "                'in_channels': 1,\n",
    "                'out_channels': 2,\n",
    "                'base_channels': 8,\n",
    "                'growth_rate': 2,\n",
    "                'depth': 3}\n",
    "\n",
    "# Training params\n",
    "epoch = 75\n",
    "batch_size = 50\n",
    "lr_rate = 1e-2\n",
    "\n",
    "model = cmodel(quilter_params, model_params, device='cuda:0', savepath = 'random')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load('16xmodel_11_15_2024/model_iteration_4.pt')\n",
    "\n",
    "#Below code is for \"per-epoch\" saved models\n",
    "state_dict = torch.load('/local/califone_backup/local_avong/AIRXD_results_1x_nopruning/3/256/repeat_4/net_epoch_50.pt')\n",
    "new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "model.model.load_state_dict(new_state_dict)\n",
    "\n",
    "model.model = model.model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TUNet(\n",
       "  (activation): ReLU()\n",
       "  (Encode_0): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (Decode_0): Sequential(\n",
       "    (0): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(8, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (Step Down 0): MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=[0, 0], dilation=1, ceil_mode=False)\n",
       "  (Step Up 0): ConvTranspose2d(16, 8, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (Encode_1): Sequential(\n",
       "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (Decode_1): Sequential(\n",
       "    (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (Step Down 1): MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=[0, 0], dilation=1, ceil_mode=False)\n",
       "  (Step Up 1): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (Final_layer_2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['data_modified_mask/battery5/Xin-1-00000-00001.tif',\n",
       "  'data_modified_mask/battery5/Xin-1-00000-00002.tif',\n",
       "  'data_modified_mask/battery5/Xin-1-00000-00003.tif',\n",
       "  'data_modified_mask/battery5/Xin-1-00000-00004.tif',\n",
       "  'data_modified_mask/battery5/Xin-1-00000-00005.tif',\n",
       "  'data_modified_mask/battery5/Xin-1-00000-00006.tif',\n",
       "  'data_modified_mask/battery5/Xin-1-00000-00007.tif',\n",
       "  'data_modified_mask/battery5/Xin-1-00000-00008.tif',\n",
       "  'data_modified_mask/battery5/Xin-1-00000-00009.tif',\n",
       "  'data_modified_mask/battery5/Xin-1-00000-00012.tif',\n",
       "  'data_modified_mask/battery5/Xin-1-00000-00013.tif',\n",
       "  'data_modified_mask/battery5/Xin-1-00000-00014.tif'],\n",
       " ['data_modified_mask/battery5/masks/Xin-1-00000-00001_mask.tif',\n",
       "  'data_modified_mask/battery5/masks/Xin-1-00000-00002_mask.tif',\n",
       "  'data_modified_mask/battery5/masks/Xin-1-00000-00003_mask.tif',\n",
       "  'data_modified_mask/battery5/masks/Xin-1-00000-00004_mask.tif',\n",
       "  'data_modified_mask/battery5/masks/Xin-1-00000-00005_mask.tif',\n",
       "  'data_modified_mask/battery5/masks/Xin-1-00000-00006_mask.tif',\n",
       "  'data_modified_mask/battery5/masks/Xin-1-00000-00007_mask.tif',\n",
       "  'data_modified_mask/battery5/masks/Xin-1-00000-00008_mask.tif',\n",
       "  'data_modified_mask/battery5/masks/Xin-1-00000-00009_mask.tif',\n",
       "  'data_modified_mask/battery5/masks/Xin-1-00000-00012_mask.tif',\n",
       "  'data_modified_mask/battery5/masks/Xin-1-00000-00013_mask.tif',\n",
       "  'data_modified_mask/battery5/masks/Xin-1-00000-00014_mask.tif'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_paths= [f for f in glob('data_modified_mask/battery5/*.tif')]\n",
    "test_mask_paths = [f for f in glob('data_modified_mask/battery5/masks/*.tif')]\n",
    "\n",
    "#Sort input/mask paths by the last part of the filename\n",
    "test_input_paths.sort(key=lambda x: x.split('/')[-1].split('_')[0])\n",
    "test_mask_paths.sort(key=lambda x: x.split('/')[-1].split('_')[0])\n",
    "\n",
    "test_input_paths, test_mask_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix as CM\n",
    "import imageio as iio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_CM(pred, labels):\n",
    "    matrix = CM(labels.ravel(), pred.ravel())\n",
    "    matrix_flat = matrix.ravel()\n",
    "    return matrix_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([484, 1, 256, 256])\n",
      "torch.Size([484, 1, 256, 256])\n",
      "torch.Size([484, 1, 256, 256])\n",
      "torch.Size([484, 1, 256, 256])\n",
      "torch.Size([484, 1, 256, 256])\n",
      "torch.Size([484, 1, 256, 256])\n",
      "torch.Size([484, 1, 256, 256])\n",
      "torch.Size([484, 1, 256, 256])\n",
      "torch.Size([484, 1, 256, 256])\n",
      "torch.Size([484, 1, 256, 256])\n",
      "torch.Size([484, 1, 256, 256])\n",
      "torch.Size([484, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "results = np.zeros((4))\n",
    "\n",
    "for i in range(len(test_input_paths)):\n",
    "    im = iio.v2.volread(test_input_paths[i])\n",
    "    label = iio.v2.volread(test_mask_paths[i])\n",
    "\n",
    "    #Prediction\n",
    "    pred = model.predict_old(im)\n",
    "\n",
    "    #Do CM calc\n",
    "    single_cm = calculate_CM(pred, label)\n",
    "\n",
    "    results += single_cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9954833662388914, 0.8208049113233288)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn = results[0]/(results[0] + results[1]+1)\n",
    "tp = results[3]/(results[3] + results[2]+1)\n",
    "\n",
    "tn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 1x model without pruning:\n",
    "#1: 79.5\n",
    "#2: 79.0\n",
    "#3: 80.9\n",
    "#4: 81.5\n",
    "#5: 82.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.10539600000001"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For 16x model\n",
    "\n",
    "#1: 90.44338\n",
    "#2: 80.34\n",
    "#3: 86.3369\n",
    "#4: 80.8867\n",
    "#5: 87.52\n",
    "\n",
    "avg = (90.44338 + 80.34 + 86.3369 + 80.8867 + 87.52) / 5\n",
    "avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating all 5 16x models on the rest of the datasets in data_modified_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validation import validate_model\n",
    "from pathlib import Path\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating depth 3, window 256 and repeat 0\n",
      "Predicting on image 0 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 0 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 11 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 0 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 11 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 0 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 11 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 12 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 13 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 0 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "[[[8.89183500e+07 2.28587000e+06 2.98200000e+03 3.11980000e+04]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[9.55395880e+07 3.53542300e+06 1.02910000e+05 3.54879000e+05]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[9.63616250e+07 3.13323900e+06 7.60000000e+01 3.78600000e+04]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[1.14066459e+08 1.98690200e+06 6.68000000e+02 6.75710000e+04]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[8.91294190e+07 1.92813000e+06 4.92000000e+03 1.75931000e+05]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]]\n",
      "Tn: [[0.97493678 0.         0.         0.         0.        ]\n",
      " [0.96431568 0.         0.         0.         0.        ]\n",
      " [0.96850853 0.         0.         0.         0.        ]\n",
      " [0.9828794  0.         0.         0.         0.        ]\n",
      " [0.97882514 0.         0.         0.         0.        ]], Tp: [[0.91272929 0.         0.         0.         0.        ]\n",
      " [0.77520042 0.         0.         0.         0.        ]\n",
      " [0.99797032 0.         0.         0.         0.        ]\n",
      " [0.99019637 0.         0.         0.         0.        ]\n",
      " [0.97278991 0.         0.         0.         0.        ]]\n",
      "Validating depth 3, window 256 and repeat 1\n",
      "Predicting on image 0 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 0 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 11 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 0 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 11 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 0 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 11 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 12 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 13 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 0 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "[[[8.89183500e+07 2.28587000e+06 2.98200000e+03 3.11980000e+04]\n",
      "  [8.93004340e+07 1.90378600e+06 2.16100000e+03 3.20190000e+04]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[9.55395880e+07 3.53542300e+06 1.02910000e+05 3.54879000e+05]\n",
      "  [9.61563940e+07 2.91861700e+06 6.69120000e+04 3.90877000e+05]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[9.63616250e+07 3.13323900e+06 7.60000000e+01 3.78600000e+04]\n",
      "  [9.70958660e+07 2.39899800e+06 2.20000000e+02 3.77160000e+04]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[1.14066459e+08 1.98690200e+06 6.68000000e+02 6.75710000e+04]\n",
      "  [1.14401775e+08 1.65158600e+06 3.33400000e+03 6.49050000e+04]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[8.91294190e+07 1.92813000e+06 4.92000000e+03 1.75931000e+05]\n",
      "  [8.95425170e+07 1.51503200e+06 9.22800000e+03 1.71623000e+05]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]]\n",
      "Tn: [[0.97493678 0.97912611 0.         0.         0.        ]\n",
      " [0.96431568 0.97054133 0.         0.         0.        ]\n",
      " [0.96850853 0.97588821 0.         0.         0.        ]\n",
      " [0.9828794  0.98576873 0.         0.         0.        ]\n",
      " [0.97882514 0.98336181 0.         0.         0.        ]], Tp: [[0.91272929 0.93674849 0.         0.         0.        ]\n",
      " [0.77520042 0.85383473 0.         0.         0.        ]\n",
      " [0.99797032 0.99417455 0.         0.         0.        ]\n",
      " [0.99019637 0.95112837 0.         0.         0.        ]\n",
      " [0.97278991 0.94896932 0.         0.         0.        ]]\n",
      "Validating depth 3, window 256 and repeat 2\n",
      "Predicting on image 0 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 0 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 11 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 0 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 11 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 0 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 11 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 12 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 13 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 0 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "[[[8.89183500e+07 2.28587000e+06 2.98200000e+03 3.11980000e+04]\n",
      "  [8.93004340e+07 1.90378600e+06 2.16100000e+03 3.20190000e+04]\n",
      "  [8.96572250e+07 1.54699500e+06 1.77600000e+03 3.24040000e+04]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[9.55395880e+07 3.53542300e+06 1.02910000e+05 3.54879000e+05]\n",
      "  [9.61563940e+07 2.91861700e+06 6.69120000e+04 3.90877000e+05]\n",
      "  [9.62596580e+07 2.81535300e+06 6.86070000e+04 3.89182000e+05]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[9.63616250e+07 3.13323900e+06 7.60000000e+01 3.78600000e+04]\n",
      "  [9.70958660e+07 2.39899800e+06 2.20000000e+02 3.77160000e+04]\n",
      "  [9.72643670e+07 2.23049700e+06 2.62000000e+02 3.76740000e+04]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[1.14066459e+08 1.98690200e+06 6.68000000e+02 6.75710000e+04]\n",
      "  [1.14401775e+08 1.65158600e+06 3.33400000e+03 6.49050000e+04]\n",
      "  [1.14480838e+08 1.57252300e+06 6.79600000e+03 6.14430000e+04]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[8.91294190e+07 1.92813000e+06 4.92000000e+03 1.75931000e+05]\n",
      "  [8.95425170e+07 1.51503200e+06 9.22800000e+03 1.71623000e+05]\n",
      "  [8.93310800e+07 1.72646900e+06 5.31700000e+03 1.75534000e+05]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]]\n",
      "Tn: [[0.97493678 0.97912611 0.98303811 0.         0.        ]\n",
      " [0.96431568 0.97054133 0.97158361 0.         0.        ]\n",
      " [0.96850853 0.97588821 0.97758178 0.         0.        ]\n",
      " [0.9828794  0.98576873 0.98644999 0.         0.        ]\n",
      " [0.97882514 0.98336181 0.98103979 0.         0.        ]], Tp: [[0.91272929 0.93674849 0.94801205 0.         0.        ]\n",
      " [0.77520042 0.85383473 0.85013216 0.         0.        ]\n",
      " [0.99797032 0.99417455 0.99306745 0.         0.        ]\n",
      " [0.99019637 0.95112837 0.90039566 0.         0.        ]\n",
      " [0.97278991 0.94896932 0.97059474 0.         0.        ]]\n",
      "Validating depth 3, window 256 and repeat 3\n",
      "Predicting on image 0 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 0 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 11 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 0 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 11 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 0 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 11 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 12 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 13 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 0 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "[[[8.89183500e+07 2.28587000e+06 2.98200000e+03 3.11980000e+04]\n",
      "  [8.93004340e+07 1.90378600e+06 2.16100000e+03 3.20190000e+04]\n",
      "  [8.96572250e+07 1.54699500e+06 1.77600000e+03 3.24040000e+04]\n",
      "  [8.93171740e+07 1.88704600e+06 1.98600000e+03 3.21940000e+04]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[9.55395880e+07 3.53542300e+06 1.02910000e+05 3.54879000e+05]\n",
      "  [9.61563940e+07 2.91861700e+06 6.69120000e+04 3.90877000e+05]\n",
      "  [9.62596580e+07 2.81535300e+06 6.86070000e+04 3.89182000e+05]\n",
      "  [9.60797770e+07 2.99523400e+06 7.28800000e+04 3.84909000e+05]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[9.63616250e+07 3.13323900e+06 7.60000000e+01 3.78600000e+04]\n",
      "  [9.70958660e+07 2.39899800e+06 2.20000000e+02 3.77160000e+04]\n",
      "  [9.72643670e+07 2.23049700e+06 2.62000000e+02 3.76740000e+04]\n",
      "  [9.71637010e+07 2.33116300e+06 2.05000000e+02 3.77310000e+04]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[1.14066459e+08 1.98690200e+06 6.68000000e+02 6.75710000e+04]\n",
      "  [1.14401775e+08 1.65158600e+06 3.33400000e+03 6.49050000e+04]\n",
      "  [1.14480838e+08 1.57252300e+06 6.79600000e+03 6.14430000e+04]\n",
      "  [1.14622877e+08 1.43048400e+06 1.35600000e+03 6.68830000e+04]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[8.91294190e+07 1.92813000e+06 4.92000000e+03 1.75931000e+05]\n",
      "  [8.95425170e+07 1.51503200e+06 9.22800000e+03 1.71623000e+05]\n",
      "  [8.93310800e+07 1.72646900e+06 5.31700000e+03 1.75534000e+05]\n",
      "  [8.96692690e+07 1.38828000e+06 9.58400000e+03 1.71267000e+05]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]]\n",
      "Tn: [[0.97493678 0.97912611 0.98303811 0.97930965 0.        ]\n",
      " [0.96431568 0.97054133 0.97158361 0.96976801 0.        ]\n",
      " [0.96850853 0.97588821 0.97758178 0.97657001 0.        ]\n",
      " [0.9828794  0.98576873 0.98644999 0.9876739  0.        ]\n",
      " [0.97882514 0.98336181 0.98103979 0.98475381 0.        ]], Tp: [[0.91272929 0.93674849 0.94801205 0.94186829 0.        ]\n",
      " [0.77520042 0.85383473 0.85013216 0.84079818 0.        ]\n",
      " [0.99797032 0.99417455 0.99306745 0.99456994 0.        ]\n",
      " [0.99019637 0.95112837 0.90039566 0.9801143  0.        ]\n",
      " [0.97278991 0.94896932 0.97059474 0.94700086 0.        ]]\n",
      "Validating depth 3, window 256 and repeat 4\n",
      "Predicting on image 0 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 0\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 0 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 11 in experiment 1\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 0 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 11 in experiment 2\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 0 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 11 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 12 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 13 in experiment 3\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 0 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 1 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 2 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 3 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 4 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 5 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 6 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 7 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 8 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 9 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "Predicting on image 10 in experiment 4\n",
      "torch.Size([484, 1, 256, 256])\n",
      "[[[8.89183500e+07 2.28587000e+06 2.98200000e+03 3.11980000e+04]\n",
      "  [8.93004340e+07 1.90378600e+06 2.16100000e+03 3.20190000e+04]\n",
      "  [8.96572250e+07 1.54699500e+06 1.77600000e+03 3.24040000e+04]\n",
      "  [8.93171740e+07 1.88704600e+06 1.98600000e+03 3.21940000e+04]\n",
      "  [8.99951860e+07 1.20903400e+06 2.28600000e+03 3.18940000e+04]]\n",
      "\n",
      " [[9.55395880e+07 3.53542300e+06 1.02910000e+05 3.54879000e+05]\n",
      "  [9.61563940e+07 2.91861700e+06 6.69120000e+04 3.90877000e+05]\n",
      "  [9.62596580e+07 2.81535300e+06 6.86070000e+04 3.89182000e+05]\n",
      "  [9.60797770e+07 2.99523400e+06 7.28800000e+04 3.84909000e+05]\n",
      "  [9.67513770e+07 2.32363400e+06 9.01620000e+04 3.67627000e+05]]\n",
      "\n",
      " [[9.63616250e+07 3.13323900e+06 7.60000000e+01 3.78600000e+04]\n",
      "  [9.70958660e+07 2.39899800e+06 2.20000000e+02 3.77160000e+04]\n",
      "  [9.72643670e+07 2.23049700e+06 2.62000000e+02 3.76740000e+04]\n",
      "  [9.71637010e+07 2.33116300e+06 2.05000000e+02 3.77310000e+04]\n",
      "  [9.77337680e+07 1.76109600e+06 6.89000000e+02 3.72470000e+04]]\n",
      "\n",
      " [[1.14066459e+08 1.98690200e+06 6.68000000e+02 6.75710000e+04]\n",
      "  [1.14401775e+08 1.65158600e+06 3.33400000e+03 6.49050000e+04]\n",
      "  [1.14480838e+08 1.57252300e+06 6.79600000e+03 6.14430000e+04]\n",
      "  [1.14622877e+08 1.43048400e+06 1.35600000e+03 6.68830000e+04]\n",
      "  [1.14414869e+08 1.63849200e+06 1.53200000e+03 6.67070000e+04]]\n",
      "\n",
      " [[8.91294190e+07 1.92813000e+06 4.92000000e+03 1.75931000e+05]\n",
      "  [8.95425170e+07 1.51503200e+06 9.22800000e+03 1.71623000e+05]\n",
      "  [8.93310800e+07 1.72646900e+06 5.31700000e+03 1.75534000e+05]\n",
      "  [8.96692690e+07 1.38828000e+06 9.58400000e+03 1.71267000e+05]\n",
      "  [8.84870980e+07 2.57045100e+06 1.39280000e+04 1.66923000e+05]]]\n",
      "Tn: [[0.97493678 0.97912611 0.98303811 0.97930965 0.98674365]\n",
      " [0.96431568 0.97054133 0.97158361 0.96976801 0.97654671]\n",
      " [0.96850853 0.97588821 0.97758178 0.97657001 0.98229962]\n",
      " [0.9828794  0.98576873 0.98644999 0.9876739  0.98588156]\n",
      " [0.97882514 0.98336181 0.98103979 0.98475381 0.97177113]], Tp: [[0.91272929 0.93674849 0.94801205 0.94186829 0.93309148]\n",
      " [0.77520042 0.85383473 0.85013216 0.84079818 0.80304725]\n",
      " [0.99797032 0.99417455 0.99306745 0.99456994 0.98181195]\n",
      " [0.99019637 0.95112837 0.90039566 0.9801143  0.97753517]\n",
      " [0.97278991 0.94896932 0.97059474 0.94700086 0.92298122]]\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the all 5 models on the rest of the datasets in modified_mask\n",
    "\n",
    "N, d = 256, 3\n",
    "\n",
    "n_repeats = 5\n",
    "datadirs = [\"battery1\", \"battery2\", \"battery3\", \"battery4\", \"Nickel\"]\n",
    "\n",
    "results = np.zeros((len(datadirs),n_repeats,4))\n",
    "start = 0\n",
    "\n",
    "#Results_master saving\n",
    "results_master_path = '/local/califone_backup/local_avong/AIRXD_results_16x_final_eval_all.pkl'\n",
    "if os.path.exists(results_master_path):\n",
    "    with open(results_master_path, 'rb') as f:\n",
    "        results_master = pickle.load(f)\n",
    "else:\n",
    "    results_master = {}\n",
    "\n",
    "#Check how many we've done so far (in case it breaks)\n",
    "if (N, d) in results_master:\n",
    "    start = np.count_nonzero(results_master[(N, d)][0,:,0])\n",
    "    results = results_master[(N, d)]\n",
    "\n",
    "#Start validating\n",
    "for repeat in range(start, n_repeats):\n",
    "    print(f'Validating depth {d}, window {N} and repeat {repeat}')\n",
    "    #Path\n",
    "    model_path =  Path('/local/califone_backup/AIRXD-CNN/16xmodel_11_15_2024')\n",
    "    model_path = model_path / f'model_iteration_{repeat}.pt'\n",
    "\n",
    "    #Load model\n",
    "    #Assume model has already been instantiated from above code\n",
    "    model.load(model_path)\n",
    "\n",
    "    #Validate\n",
    "    validate_model(model, results, repeat)\n",
    "\n",
    "    #Aggregate results\n",
    "    print(results)\n",
    "    tn = results[:,:,0]/(results[:,:,0] + results[:,:,1]+1)\n",
    "    tp = results[:,:,3]/(results[:,:,3] + results[:,:,2]+1)\n",
    "\n",
    "    print(f'Tn: {tn}, Tp: {tp}')\n",
    "\n",
    "    results_master[(N, d)] = np.stack((tn, tp), axis=2)\n",
    "\n",
    "    #Save results\n",
    "    with open(results_master_path, 'wb') as f:\n",
    "        pickle.dump(results_master, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airxd_cnn_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
